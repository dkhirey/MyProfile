%% start of file `template.tex'.
%% Copyright 2006-2013 Xavier Danaux (xdanaux@gmail.com).
%
% This work may be distributed and/or modified under the
% conditions of the LaTeX Project Public License version 1.3c,
% available at http://www.latex-project.org/lppl/.


\documentclass[11pt,a4paper,roman]{moderncv}        % possible options include font size ('10pt', '11pt' and '12pt'), paper size ('a4paper', 'letterpaper', 'a5paper', 'legalpaper', 'executivepaper' and 'landscape') and font family ('sans' and 'roman')

% modern themes
\moderncvstyle{banking}                            % style options are 'casual' (default), 'classic', 'oldstyle' and 'banking'
\moderncvcolor{blue}                                % color options 'blue' (default), 'orange', 'green', 'red', 'purple', 'grey' and 'black'
%\renewcommand{\familydefault}{\sfdefault}         % to set the default font; use '\sfdefault' for the default sans serif font, '\rmdefault' for the default roman one, or any tex font name
\nopagenumbers{}                                  % uncomment to suppress automatic page numbering for CVs longer than one page

% character encoding
\usepackage[utf8]{inputenc}
\usepackage{fontawesome}
\usepackage{fontspec}
\usepackage{tabularx}
\usepackage{ragged2e}
\usepackage{fancyhdr}

\fancyhf{}
%\rhead{Overleaf}
%\lhead{Guides and tutorials}
%\lhead{\fontsize{9pt}{11pt}\selectfont Name}
\lfoot{\fontsize{9pt}{11pt} \color{gray} \selectfont Private Confidential}
\cfoot{\fontsize{9pt}{11pt} \color{gray} \selectfont Page \thepage}
\rfoot{\fontsize{9pt}{11pt} \color{gray} \selectfont Last Updated : June 2021}


% if you are not using xelatex ou lualatex, replace by the encoding you are using
%\usepackage{CJKutf8}                              % if you need to use CJK to typeset your resume in Chinese, Japanese or Korean

% adjust the page margins
\usepackage[scale=0.8]{geometry}
\usepackage{multicol}
%\setlength{\hintscolumnwidth}{3cm}                % if you want to change the width of the column with the dates
%\setlength{\makecvtitlenamewidth}{10cm}           % for the 'classic' style, if you want to force the width allocated to your name and avoid line breaks. be careful though, the length is normally calculated to avoid any overlap with your personal info; use this at your own typographical risks...

\usepackage{import}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    urlcolor=blue
    }

% personal data
\name{Deepak}{Khirey} 


% \title{Curriculum Vitae}                               % optional, remove / comment the line if not wanted
\address{Data Scientist}{Azure Cloud Consultant}{Solution Architect}% optional, remove / comment the line if not wanted; the "postcode city" and and "country" arguments can be omitted or provided empty
% \phone[mobile]{909-839-3097}                   % optional, remove / comment the line if not wanted
% \phone[fixed]{01234 123456}                    % optional, remove / comment the line if not wanted
%\phone[fax]{+3~(456)~789~012}                      % optional, remove / comment the line if not wanted
% \email{xpan1@swarthmore.edu}                               % optional, remove / comment the line if not wanted
% \homepage{shawnpan.me}                         % optional, remove / comment the line if not wanted
% \extrainfo{}                 % optional, remove / comment the line if not wanted
%\photo[64pt][0.4pt]{picture}                       % optional, remove / comment the line if not wanted; '64pt' is the height the picture must be resized to, 0.4pt is the thickness of the frame around it (put it to 0pt for no frame) and 'picture' is the name of the picture file
%\quote{Some quote}                                 % optional, remove / comment the line if not wanted

% to show numerical labels in the bibliography (default is to show no labels); only useful if you make citations in your resume
%\makeatletter
%\renewcommand*{\bibliographyitemlabel}{\@biblabel{\arabic{enumiv}}}
%\makeatother
%\renewcommand*{\bibliographyitemlabel}{[\arabic{enumiv}]}% CONSIDER REPLACING THE ABOVE BY THIS

% bibliography with mutiple entries
%\usepackage{multibib}
%\newcites{book,misc}{{Books},{Others}}
  
\newcommand*{\customcventry}[7][.25em]{
  \begin{tabular}{@{}l} 
    {\bfseries #4}
  \end{tabular}
  \hfill% move it to the right
  \begin{tabular}{l@{}}
     {\bfseries #5}
  \end{tabular} \\
  \begin{tabular}{@{}l} 
    {\itshape #3}
  \end{tabular}
  \hfill% move it to the right
  \begin{tabular}{l@{}}
     {\itshape #2}
  \end{tabular}
  \ifx&#7&%
  \else{\\%
    \begin{minipage}{\maincolumnwidth}%
      \small#7%
    \end{minipage}}\fi%
  \par\addvspace{#1}}
  
\newcommand*{\customcvproject}[4][.25em]{
%   \vfill\noindent
  \begin{tabular}{@{}l} 
    {\bfseries #2}
  \end{tabular}
  \hfill% move it to the right
  \begin{tabular}{l@{}}
     {\itshape #3}
  \end{tabular}
  \ifx&#4&%
  \else{\\%
    \begin{minipage}{\maincolumnwidth}%
      \small#4%
    \end{minipage}}\fi%
  \par\addvspace{#1}}

\setlength{\tabcolsep}{12pt}

%----------------------------------------------------------------------------------
%            content
%----------------------------------------------------------------------------------
\begin{document}
%\begin{CJK*}{UTF8}{gbsn}                          % to typeset your resume in Chinese using CJK
%-----       resume       ---------------------------------------------------------
\makecvtitle
\vspace*{-23mm}
\bigbreak{}
\begin{center}
\begin{tabular}{c c }
 \faMobile\enspace \href{tel:+91-845-299-2813}{+91-845-299-2813}  & 
 \faEnvelopeO\enspace \href{mailto:deepakkhirey@gmail.com}{deepakkhirey@gmail.com} & 
 \faGithub\enspace \href{https://github.com/dkhirey}{github/dkhirey} & 
 \faGlobe\enspace \href{https://www.linkedin.com/in/deepakkhirey}{linkedin/deepakkhirey}\\
\end{tabular}
\end{center}

% \hline{}

\section{SUMMARY}
{\begin{itemize}
    \item Leading as Principal Data Scientist to help customers to save 2-5\% in Plant Production Operations cost by implementing Industrial IoT, Manufacturing Analytics programs
    \item Consulted as Data Architect to conceptualize and remodel on-prem application landscape into Azure cloud-based analytics environment as a part of Enterprise Cloud Transformation journey for Global Automobile Manufacturer
    \item Spearheaded Data Engineering team of Connected Vehicles program to implement and optimize End-to-End Data pipeline that improved Service Efficiency by bringing down response time from 8 hours to 2 hours and avoided 10\% potential Warranty Claims
    \item Delivered 4 large scale Global Implementations of Product Design and Product Lifecycle Management as a Solution Architect to modernize Engineering Change Release processes
    \item Accomplished 16+ years of experience in Manufacturing - Automotive Domain including  Team Building and Mentorship, Customer Relationship Management and Program Management
\end{itemize}}


\section{EDUCATION}
{\customcventry{December 2019}{MS in Data Science}{\href{https://www.indiana.edu/}{Indiana University of Bloomington}}{IN, USA}{}{}}
{\customcventry{June 2003}{Bachelor of Engineering in Mechanical}{\href{http://www.unipune.ac.in/}{Pune University}}{MH, India}{}{}}

\section{CERTIFICATIONS}
{\begin{itemize}
    \item {\href{https://www.credly.com/badges/a6183143-bff0-41e2-b81c-c2879f50c19d/public_url}{Azure Data Scientist Associate - DP100}}
    \item {\href{https://www.credly.com/badges/e2f12548-835d-4d8f-9355-0a157df89709/public_url}{Azure Fundamentals - AZ900}} 
\end{itemize}}

\section{SKILL SET}
{\begin{itemize}
  \item \textbf{Machine Learning Techniques} - Deep Learning, Timeseries Forecasting, NLP, Computer Vision, Regression, Classification, Clustering, Web Scraping
  \item \textbf{Azure Cloud Modules} - Machine Learning Services, Databricks, HDInsights, Data Factory, Function Apps, Logic Apps, Eventhub, IotHub, Stream Analytics, CosmosDB, Datalake Services
  \item \textbf{BigData Applications} - Spark, Kafka, Hive, Sqoop, HBase, Oozie, Hadoop 2.7, MapReduce
  \item \textbf{Programming Languages} - Python, Scala, Java, PL/SQL
  \item \textbf{Data Visualization Tools} - PowerBI, Tableau, Qlikview
%   \item \textbf{Agile Applications} - Jira, Confluence, GitHub
\end{itemize}
}

\clearpage

\section{EXPERIENCE}

{\customcvproject{\href{https://www.tcs.com/plant-solutions-and-services}{Principal Data Scientist – Plant Solutions Services at TCS}}{January 2020 - Present}
    {\begin{itemize}
        \item Leading Manufacturing Analytics initiatives under Industry 4.0 umbrella across 5 large customer accounts to establish sustainable analytics engagements
        \item Organizing workshops with customer stakeholders to formulate Business Case, Requirement Gathering, Functional Inputs, Data Feasibility Study, and Design Thinking as an early engagement activity
        \item Training Machine Learning model iteratively to achieve targeted accuracy and deploying trained model in Customer's Application Landscape
        \item Directing analytics teams for Data Acquisition, Data Profiling and Cleanup and Feature Engineering to automate Data Flows
        \item Co-ordinating Review meetings with the customer to explain the trained model and its significance in domain context
        \item Recruiting / Mentoring resources and enable them to monitor and support the deployed application
        \end{itemize}
    }
}

\bigbreak

{\customcvproject{ {Data Architect – Advanced Analytics at \href{https://www.fcagroup.com/en-US/pages/home.aspx}{Fiat Chrysler}}}{April 2019 - December 2019}
    {\begin{itemize}
        \item Conceptualized and Drafted strategy for transition from on-prem ecosystem to Azure Cloud environment as part of FCA Global Cloud Transformation Initiative
        \item Brainstormed roadmap to Promote Cloud adaption for new analytics projects, maintain a Hybrid Cloud environment during the transition phase, and plan sun-downing of the on-prem system in a phased manner
        \item Analyzed Data Sources, Data Consumption Patterns, and Analytics Applications to streamline Data Flows to ensure efficient resource utilization
        \item Defined multi-layered Data Lake Architecture to achieve Data Governance objectives and facilitate analytics use cases
        \item Evaluated leading Data Analytics Platforms in the market and prepared scorecard to finalize the most suitable solution to augment future Application landscape
        \item Collaborated with customer's Enterprise Architecture team for Networking, Data Security, and other business aspects
        \end{itemize}
    }
}

\bigbreak

{\customcvproject{ \href{https://www.cummins.com/parts-and-service/digital-products-and-services/connected-diagnostics}{Data Engineer – Advanced Analytics at Cummins Inc.}}{January 2016 - March 2019}
  {\begin{itemize}
    \item Steered Data Engineering team to ingest field data from Cummins Service Stations and Telematics data from Engine heartbeats in real-time and execute algorithms to predict Fault occurrences and possible downtime
    \item Devised End-to-end Data Pipelines and Developed Applications in Scala for Data Transformations
    \item Generated Data Quality matrix for Data Consistency requirements and established Dashboards in PowerBI to report analysis results
    \item Formulated Data Storage and Retention strategy at different Data Wrangling Stages
  \end{itemize}
  }
}

\section{ACHIEVEMENTS}

{\customcventry{}{\textbf{Intelligent Production Optimizer}}{Unit Finalist at TCS Innovista 2020}{September 2020}{}{}}
{
\begin{itemize}
    \item Innovation to provide insights to the Production Manager on Line Balancing and Product Order Mix so that system can self identify and prescribe the best sequence of orders that would take the least time and improve assembly line productivity
    \item Ideated and demonstrated ML-powered feedback mechanism to bridge the gap between Production Sequence Planning and Historical Order Execution timelines
\end{itemize}
}


\bigbreak

{\customcventry{}{\textbf{Prediction of Logistical Delays of Delivery Trucks based on Real Time Telematics data}}{Winner of CTO Hackathon at Fiat Chrysler}{November 2019}{}{}}
{
\begin{itemize}
    \item Outlined solution to enable the business to monitor Supply Chain Delivery status, predict ETA using Google Maps API and advanced alerts on possible delays
    \item Built prototype of Custom HTTP Source connector using Confluent Hub to use Apache Kafka as a Streaming platform to ingest data from Telematics Devices to On-Prem PostgreSQL Data Lake at real-time
\end{itemize}
}

\section{WORK HISTORY}

% {\customcventry{January 2020 - Present}{Principal Data Scientist}{\href{https://www.tcs.com/}{Tata Consultancy Services}}{Pune, India}{}{}}
% {\customcventry{March 2019 - December 2019}{Data Architect}{\href{https://www.tcs.com/}{Tata Consultancy Services}}{Detroit, MI}{}{}}
{\customcventry{January 2016 - Present}{Data Analytics Lead}{\href{https://www.tcs.com/}{Tata Consultancy Services}}{Columbus, IN | Detroit, MI | Pune, India}{}{}}
{\customcventry{December 2010 - December 2015}{PLM Solution Architect}{\href{https://www.tcs.com/}{Tata Consultancy Services}}{Columbus, IN | Pune, India}{}{}}
{\customcventry{March 2010 - November 2010}{Development Team Lead}{\href{https://www.techmahindra.com/en-in/}{Mahindra Satyam Computer Systems}}{Hyderabad, India}{}{}}
{\customcventry{October 2007 - February 2010}{Software Developer}{\href{https://www.kpit.com/}{KPIT Cummins Infosystems}}{Pune, India}{}{}}
{\customcventry{July 2005 - September 2007}{Software Quality Analyst}{\href{https://www.ptc.com/}{Parametric Technology Corporation}}{Pune, India}{}{}}
{\customcventry{May 2004 - June 2005}{CAD Design Engineer}{\href{https://www.mahle.com/}{Mahle Filter Systems}}{Pune, India}{}{}}


% \textbf{Tata Consultancy Services}  \hfill{\textbf{December 2010 - Present}}\\
% \textbf{Mahindra Satyam Computer Systems}  \hfill{\textbf{March 2010 - November 2010}}\\
% \textbf{KPIT Cummins Infosystems}  \hfill{\textbf{October 2007 - February 2010}}\\
% \textbf{Parametric Technology Corporation}  \hfill{\textbf{July 2005 - September 2007}}\\
% \textbf{Mahle Filter Systems}  \hfill{\textbf{May 2004 - June 2005}}


% Publications from a BibTeX file without multibib
%  for numerical labels: \renewcommand{\bibliographyitemlabel}{\@biblabel{\arabic{enumiv}}}% CONSIDER MERGING WITH PREAMBLE PART
%  to redefine the heading string ("Publications"): \renewcommand{\refname}{Articles}
\nocite{*}
\bibliographystyle{plain}
\bibliography{publications}                        % 'publications' is the name of a BibTeX file

% Publications from a BibTeX file using the multibib package
%\section{Publications}
%\nocitebook{book1,book2}
%\bibliographystylebook{plain}
%\bibliographybook{publications}                   % 'publications' is the name of a BibTeX file
%\nocitemisc{misc1,misc2,misc3}
%\bibliographystylemisc{plain}
%\bibliographymisc{publications}                   % 'publications' is the name of a BibTeX file

%-----       letter       ---------------------------------------------------------

\end{document}


%% end of file `template.tex'.
